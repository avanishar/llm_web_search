# Google improves Gemini AI image editing with “nano banana” model - Ars Technica

**Source:** https://arstechnica.com/ai/2025/08/google-improves-gemini-ai-image-editing-with-nano-banana-model/

**Scraped on:** 2025-08-31 23:19:46

---

Photoshop who?
Google improves Gemini AI image editing with “nano banana” model
Gemini 2.5 Flash Image is currently atop LMArena's image-editing leaderboard.
Ryan Whitwam
–
Aug 26, 2025 12:03 pm
|
64
Credit:

          
          Ryan Whitwam
Credit:

          
          Ryan Whitwam
Text
        settings
Story text
Size
Small
Standard
Large
Width
*
Standard
Wide
Links
Standard
Orange
* Subscribers only
Learn more
Minimize to nav
Something unusual happened in the world of AI image editing recently. A new model, known as "nano banana," started making the rounds with impressive abilities that landed it at the top of the LMArena leaderboard. Now, Google has
revealed
that nano banana is an innovation from Google DeepMind, and it's being rolled out to the Gemini app today.
AI image editing allows you to modify images with a prompt rather than mucking around in Photoshop. Google first provided editing capabilities in Gemini earlier this year, and the model was
more than competent out of the gate
. But like all generative systems, the non-deterministic nature meant that elements of the image would often change in unpredictable ways. Google says nano banana (technically Gemini 2.5 Flash Image) has unrivaled consistency across edits—it can actually remember the details instead of rolling the dice every time you make a change.
Google says subjects will retain their appearance as you edit.
Google says subjects will retain their appearance as you edit.
This unlocks several interesting uses for AI image editing. Google suggests uploading a photo of a person and changing their style or attire. For example, you can reimagine someone as a matador or a '90s sitcom character. Because the nano banana model can maintain consistency through edits, the results should still look like the person in the original source image. This is also the case when you make multiple edits in a row. Google says that even down the line, the results should look like the original source material.
The goodest boy.
The goodest boy.
Gemini's enhanced image editing can also merge multiple images, allowing you to use them as the fodder for a new image of your choosing. Google's example below takes separate images of a woman and a dog and uses them to generate a new snapshot of the dog getting cuddles—possibly the best use of generative AI yet. Gemini image editing can also merge things in more abstract ways and will follow your prompts to create just about anything that doesn't run afoul of the model's guard rails.
The model remembers details instead of generating completely new things every time.
The model remembers details instead of generating completely new things every time.
As with other Google AI image-generation models, the output of Gemini 2.5 Flash Image always comes with a visible "AI" watermark in the corner. The image also has an invisible SynthID digital watermark that can be detected even after moderate modification.
You can give the new native image editing a shot today in the Gemini app. Google says the new image model will also roll out soon in the Gemini API, AI Studio, and Vertex AI for developers.
Ryan Whitwam
Senior Technology Reporter
Ryan Whitwam
Senior Technology Reporter
Ryan Whitwam is a senior technology reporter at Ars Technica, covering the ways Google, AI, and mobile technology continue to change the world. Over his 20-year career, he's written for Android Police, ExtremeTech, Wirecutter, NY Times, and more. He has reviewed more phones than most people will ever own. You can
follow him on Bluesky
, where you will see photos of his dozens of mechanical keyboards.
64 Comments